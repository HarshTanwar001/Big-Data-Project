{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "\n",
    "# ensemble modelling\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading prebuilt model structures stored as '[MODEL].h5'\n",
    "\n",
    "rf = pickle.load(open('../models/h5s/random-forest.h5', 'rb'))\n",
    "lr = pickle.load(open('../models/h5s/logistic-regression.h5', 'rb'))\n",
    "lda = pickle.load(open('../models/h5s/linear-discriminant-analysis.h5', 'rb'))\n",
    "knn = pickle.load(open('../models/h5s/kNN.h5', 'rb'))\n",
    "cart = pickle.load(open('../models/h5s/CART.h5', 'rb'))\n",
    "svm = pickle.load(open('../models/h5s/support-vector-machine.h5', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49999\n"
     ]
    }
   ],
   "source": [
    "columns = [\"date\", \"time\", \"FC1_Read_Input_Register\", \"FC2_Read_Discrete_Value\", \"FC3_Read_Holding_Register\", \"FC4_Read_Coil\", \"label\", \"type\"]\n",
    "\n",
    "IoT = pd.read_csv(\"../data/Test_Modbus.csv\", low_memory=False)\n",
    "IoT = IoT.dropna()\n",
    "\n",
    "# encoding string type variables to numeric type (required for model training)\n",
    "encoder = LabelEncoder()\n",
    "IoT['type'] = encoder.fit_transform(IoT['type'])\n",
    "\n",
    "x = IoT.drop(['label', 'date', 'time', 'type'], axis=1)\n",
    "y = IoT['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[('RF', rf), ('LR', lr), ('LDA', lda), ('KNN', knn), ('CART', cart), ('SVM', svm)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/h5s/VC.h5'\n",
    "pickle.dump(voting, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "voting.fit(x_train, y_train)\n",
    "training_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = voting.predict(x_test)\n",
    "test_time = time.time() - start\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5988\n",
      "Precision: 0.6775604502971861\n",
      "Recall: 0.8314357123021383\n",
      "F1_Score: 0.6891665951286284\n",
      "Training Time: 180.80464911460876s\n",
      "Testing Time: 53.95462608337402s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.43      0.59      1664\n",
      "           1       0.98      0.71      0.83       750\n",
      "           2       0.55      0.99      0.70      4788\n",
      "           3       0.00      0.00      0.00      2725\n",
      "           4       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.49      0.43      0.42     10000\n",
      "weighted avg       0.49      0.60      0.50     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "recall = recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1_Score:', f1)\n",
    "print(f'Training Time: {training_time}s')\n",
    "print(f'Testing Time: {test_time}s')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 0.455891         0.65163        0.571981        0.366899     1607.571023"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8899eb02dfbc033aab5733bdae1bd213fa031d40331094008e8673d99ebab63"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
